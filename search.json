[
  {
    "objectID": "prediction.html",
    "href": "prediction.html",
    "title": "Stop and Searchs",
    "section": "",
    "text": "The goal of this project is to predict the daily number of “use of force” (UoF) incidents by the police in London. This prediction could aid in resource allocation and planning for law enforcement agencies, ensuring they can effectively manage and respond to incidents.\n\n\n\nThe steps taken to prepare the data can be seen in Figure 1.\n\n\n\nFigure 1: Data Preprocessing Flowchart\n\n\n\n\n\nPrediction, a core concept in machine learning and data science, involves forecasting continuous outcomes based on input data. In this project, predictive modeling techniques are used to estimate the number of UoF incidents on a given day. By analysing patterns and trends in historical data, these models aim to provide accurate forecasts that can aid in operational decision-making.\n\n\nThe primary regression model used to predict the daily number of UoF incidents is XGBoost. Here’s a brief introduction to the model:\nXGBoost:\nXGBoost (Extreme Gradient Boosting) is an advanced machine learning algorithm that uses boosting techniques to improve prediction accuracy. It is known for its high performance and efficiency in handling large datasets with complex patterns.\n\n\n\n\nThe performance of the XGBoost model is evaluated using common regression metrics such as Root Mean Squared Error (RMSE) and R-squared (R²). The results indicate that XGBoost provides high prediction accuracy.\nRoot Mean Squared Error (RMSE): - XGBoost: RMSE = 36.69\nR-squared (R²): - XGBoost: R² = 0.897\nThe RMSE value indicates that, on average, the predicted number of UoF incidents deviates from the actual number by approximately 36.69 incidents. The R² value suggests that 89.7% of the variability in the number of daily UoF incidents is explained by the model. These metrics highlight the model’s effectiveness in providing accurate predictions and capturing the underlying patterns in the data.\n\n\n\nFigure 2: Scatter plot illustratating the relationship between actual values and the predicted values generated by the XGBoost model. The x-axis represents the actual values, while the y-axis denotes the predicted values. Each orange dot corresponds to a pair of actual and predicted values. A red dashed line labeled “y=x” indicates the ideal scenario where the predicted values exactly match the actual values.\n\n\nMany points in the scatter plot are closely aligned with the red dashed line, indicating that the XGBoost model has a strong predictive ability. When the points lie directly on this line, it means that the predicted values are equal to the actual values. This close alignment suggests that the model captures the underlying pattern in the data effectively, providing reliable predictions for a substantial portion of the dataset.\nHowever, some points deviate from the red dashed line, suggesting prediction errors. The spread of these points indicates the degree of error in the model’s predictions. A wider spread away from the line suggests greater prediction error, while a narrower spread indicates higher accuracy. Notably, the majority of data points are clustered in the mid-range values of both actual and predicted values. This concentration suggests that the model performs consistently well within this range. However, at the extremes (both high and low values), the spread appears larger, indicating that the model might have difficulty predicting extreme values accurately.\n\n\n\nFigure 3: Bar chart showing the relative importance of various features used in the XGBoost model. The x-axis represents the importance score, while the y-axis lists the features. Each bar indicates the importance of a feature in predicting the target variable, with longer bars signifying higher importance.\n\n\nThe chart clearly shows that the feature ‘count_7_day_avg’ has the highest importance score by a substantial margin. This suggests that the average count over the past seven days is the most influential factor in the model’s predictions. Such a high importance score indicates that this feature provides significant predictive power and has a strong correlation with the target variable.\nFollowing ‘count_7_day_avg’, the feature ‘mob_count’ also shows notable importance, albeit much lower than the top feature. This suggests that while the count of mobile events contributes to the model’s predictions, its impact is significantly less compared to the seven-day average count. Other features such as ‘ULSD: Pump price (p/litre)’, ‘ULSP: Pump price (p/litre)’, and ‘is bank holiday’ have minimal importance scores, indicating that these factors contribute very little to the model’s predictive ability.\nInterestingly, several weather-related features like ‘precipitation_sum’, ‘rain_sum’, and ‘apparent_temperature_mean’ have negligible importance. This suggests that weather conditions, despite being potentially relevant in some contexts, do not significantly influence the predictions in this specific model. Similarly, temporal features such as ‘WeekOfYear’, ‘DayOfYear’, and ‘DayOfWeek’ also show low importance scores, indicating that the specific time periods do not greatly impact the model’s predictions."
  },
  {
    "objectID": "classification.html",
    "href": "classification.html",
    "title": "Stop and Searchs",
    "section": "",
    "text": "Classification is a concept in machine learning and data science, used to predict categorical outcomes based on input data. In this project, classification techniques are employed to determine the result of police SAS procedures in London. Specifically, the goal is to classify each stop as either resulting in a significant outcome, such as an arrest (true), or yielding no incriminating evidence (false). By analysing various features from the SAS data, including temporal, demographic, and spatial (location) variables, classification models can help predict the likelihood of a meaningful outcome, aiding in the evaluation and optimisation of law enforcement practices.\n\n\n\nThe steps taken to prepare the data can be seen in Figure 1.\n\n\n\nFigure 1: Data Preprocessing Flowchart\n\n\n\n\n\nTwo different classification models are used to predict the outcomes of police stop and search incidents: Logistic Regression and XGBoost. Here’s a brief introduction to each model:\n\n\nx\n\n\n\ny\n\n\n\n\nXGBoost appears to have a better accuracy than logistic regression.\n\n\n\nFigure 2: Barchart showing accuracy of the classifcation models on the test data.\n\n\nThis is supported by a confusion matrix, allowing identification of type 1 & 2 errors. In these matrices, type 1 errors (False Positives) are represented in the upper right cell of each matrix, while type 2 errors (False Negatives) are in the lower left cell. Type 1 error, also known as a false positive, occurs when the model incorrectly predicts a positive outcome for a stop and search operation, i.e., predicting that an illegal item will be found when it is not. Type 2 error, or false negative, occurs when the model incorrectly predicts a negative outcome, i.e., predicting that no illegal item will be found when it is.\nThese errors have significant implications for police operations and public trust. A high number of false positives (type 1 errors) could lead to unnecessary searches, potentially eroding public trust and wasting police resources. For instance, the Logistic Regression model has 15,370 false positives, whereas the XGBoost model has 15,985, indicating that XGBoost might lead to slightly more unnecessary searches compared to Logistic Regression. This increase in unnecessary searches could result in more civilian inconvenience and dissatisfaction, which is particularly sensitive in the context of police-community relations.\nOn the other hand, a high number of false negatives (type 2 errors) could mean that illegal items are missed during searches, which could have public safety implications. The Logistic Regression model shows 18,181 false negatives compared to only 10,505 for the XGBoost model. This substantial reduction in false negatives with the XGBoost model indicates a higher likelihood of detecting illegal items during stop and search operations, thus potentially enhancing public safety and the efficacy of police work.\nBalancing these errors is crucial. The choice of model thus depends on the context-specific cost of these errors. For the London police, the XGBoost model’s lower false negative rate suggests it is more effective at identifying actual instances where illegal items are present, thereby potentially improving crime prevention and intervention outcomes. However, the slight increase in false positives must be managed carefully to avoid unnecessary intrusions and maintain public trust. Ultimately, the decision between these models requires a nuanced consideration of the trade-offs between operational efficiency, public safety, and community relations.\n\n\n\nFigure 3: Confusion matrix showing the number of correct and incorrect predictions made by the models.\n\n\nThe ROC curves for the Logistic Regression and XGBoost models illustrate their performance in distinguishing between positive and negative outcomes in stop and search operations. The area under the curve (AUC) is a key metric in these plots, with the Logistic Regression model achieving an AUC of 0.71 and the XGBoost model achieving a higher AUC of 0.81. The higher AUC for the XGBoost model indicates a better overall performance in correctly identifying true positives while minimizing false positives compared to the Logistic Regression model. This demonstrates that the XGBoost model is more effective in differentiating between individuals who possess illegal items and those who do not, which can significantly impact the effectiveness and efficiency of stop and search operations.\n\n\n\nFigure 4: ROC curves showing the true positive rate against the false positive rate for the Logistic Regression and XGBoost models."
  }
]