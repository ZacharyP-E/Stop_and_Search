[
  {
    "objectID": "prediction.html",
    "href": "prediction.html",
    "title": "Stop and Searchs",
    "section": "",
    "text": "The goal of this project is to predict the daily number of “use of force” (UoF) incidents by the police in London. This prediction could aid in resource allocation and planning for law enforcement agencies, ensuring they can effectively manage and respond to incidents.\n\n\n\nPrediction, a core concept in machine learning and data science, involves forecasting continuous outcomes based on input data. In this project, predictive modeling techniques are used to estimate the number of UoF incidents on a given day. By analysing patterns and trends in historical data, these models aim to provide accurate forecasts that can aid in operational decision-making.\n\n\nThe primary regression model used to predict the daily number of UoF incidents is XGBoost. Here’s a brief introduction to the model:\nXGBoost:\nXGBoost (Extreme Gradient Boosting) is an advanced machine learning algorithm that uses boosting techniques to improve prediction accuracy. It is known for its high performance and efficiency in handling large datasets with complex patterns.\n\n\n\n\nThe performance of the XGBoost model is evaluated using common regression metrics such as Root Mean Squared Error (RMSE) and R-squared (R²). The results indicate that XGBoost provides high prediction accuracy.\nRoot Mean Squared Error (RMSE): - XGBoost: RMSE = 36.69\nR-squared (R²): - XGBoost: R² = 0.897\nThe RMSE value indicates that, on average, the predicted number of UoF incidents deviates from the actual number by approximately 36.69 incidents. The R² value suggests that 89.7% of the variability in the number of daily UoF incidents is explained by the model. These metrics highlight the model’s effectiveness in providing accurate predictions and capturing the underlying patterns in the data.\n\n\n\nFigure 1: Scatter plot illustratating the relationship between actual values and the predicted values generated by the XGBoost model. The x-axis represents the actual values, while the y-axis denotes the predicted values. Each orange dot corresponds to a pair of actual and predicted values. A red dashed line labeled “y=x” indicates the ideal scenario where the predicted values exactly match the actual values.\n\n\nMany points in the scatter plot are closely aligned with the red dashed line, indicating that the XGBoost model has a strong predictive ability. When the points lie directly on this line, it means that the predicted values are equal to the actual values. This close alignment suggests that the model captures the underlying pattern in the data effectively, providing reliable predictions for a substantial portion of the dataset.\nHowever, some points deviate from the red dashed line, suggesting prediction errors. The spread of these points indicates the degree of error in the model’s predictions. A wider spread away from the line suggests greater prediction error, while a narrower spread indicates higher accuracy. Notably, the majority of data points are clustered in the mid-range values of both actual and predicted values. This concentration suggests that the model performs consistently well within this range. However, at the extremes (both high and low values), the spread appears larger, indicating that the model might have difficulty predicting extreme values accurately.\n\n\n\nFigure 2: Bar chart showing the relative importance of various features used in the XGBoost model. The x-axis represents the importance score, while the y-axis lists the features. Each bar indicates the importance of a feature in predicting the target variable, with longer bars signifying higher importance.\n\n\nThe chart clearly shows that the feature ‘count_7_day_avg’ has the highest importance score by a substantial margin. This suggests that the average count over the past seven days is the most influential factor in the model’s predictions. Such a high importance score indicates that this feature provides significant predictive power and has a strong correlation with the target variable.\nFollowing ‘count_7_day_avg’, the feature ‘mob_count’ also shows notable importance, albeit much lower than the top feature. This suggests that while the count of mobile events contributes to the model’s predictions, its impact is significantly less compared to the seven-day average count. Other features such as ‘ULSD: Pump price (p/litre)’, ‘ULSP: Pump price (p/litre)’, and ‘is bank holiday’ have minimal importance scores, indicating that these factors contribute very little to the model’s predictive ability.\nInterestingly, several weather-related features like ‘precipitation_sum’, ‘rain_sum’, and ‘apparent_temperature_mean’ have negligible importance. This suggests that weather conditions, despite being potentially relevant in some contexts, do not significantly influence the predictions in this specific model. Similarly, temporal features such as ‘WeekOfYear’, ‘DayOfYear’, and ‘DayOfWeek’ also show low importance scores, indicating that the specific time periods do not greatly impact the model’s predictions."
  },
  {
    "objectID": "classification.html",
    "href": "classification.html",
    "title": "Stop and Searchs",
    "section": "",
    "text": "Classification is a concept in machine learning and data science, used to predict categorical outcomes based on input data. In this project, classification techniques are employed to determine the result of police SAS procedures in London. Specifically, the goal is to classify each stop as either resulting in a significant outcome, such as an arrest (true), or yielding no incriminating evidence (false). By analysing various features from the SAS data, including temporal, demographic, and spatial (location) variables, classification models can help predict the likelihood of a meaningful outcome, aiding in the evaluation and optimisation of law enforcement practices.\n\n\n\nThe steps taken to prepare the data can be seen in Figure 1.\n\n\n\nFigure 1: Data Preprocessing Flowchart\n\n\n\n\n\nTwo different classification models are used to predict the outcomes of police stop and search incidents: Logistic Regression and XGBoost. Here’s a brief introduction to each model:\n\n\nx\n\n\n\ny\n\n\n\n\nXGBoost appears to have a better accuracy than logistic regression.\n\n\n\nFigure 2: Barchart showing accuracy of the classifcation models on the test data.\n\n\nThis is supported by a confusion matrix, allowing identification of type 1 & 2 errors. In these matrices, type 1 errors (False Positives) are represented in the upper right cell of each matrix, while type 2 errors (False Negatives) are in the lower left cell. Type 1 error, also known as a false positive, occurs when the model incorrectly predicts a positive outcome for a stop and search operation, i.e., predicting that an illegal item will be found when it is not. Type 2 error, or false negative, occurs when the model incorrectly predicts a negative outcome, i.e., predicting that no illegal item will be found when it is.\nThese errors have significant implications for police operations and public trust. A high number of false positives (type 1 errors) could lead to unnecessary searches, potentially eroding public trust and wasting police resources. For instance, the Logistic Regression model has 15,370 false positives, whereas the XGBoost model has 15,985, indicating that XGBoost might lead to slightly more unnecessary searches compared to Logistic Regression. This increase in unnecessary searches could result in more civilian inconvenience and dissatisfaction, which is particularly sensitive in the context of police-community relations.\nOn the other hand, a high number of false negatives (type 2 errors) could mean that illegal items are missed during searches, which could have public safety implications. The Logistic Regression model shows 18,181 false negatives compared to only 10,505 for the XGBoost model. This substantial reduction in false negatives with the XGBoost model indicates a higher likelihood of detecting illegal items during stop and search operations, thus potentially enhancing public safety and the efficacy of police work.\nBalancing these errors is crucial. The choice of model thus depends on the context-specific cost of these errors. For the London police, the XGBoost model’s lower false negative rate suggests it is more effective at identifying actual instances where illegal items are present, thereby potentially improving crime prevention and intervention outcomes. However, the slight increase in false positives must be managed carefully to avoid unnecessary intrusions and maintain public trust. Ultimately, the decision between these models requires a nuanced consideration of the trade-offs between operational efficiency, public safety, and community relations.\n\n\n\nFigure 3: Confusion matrix showing the number of correct and incorrect predictions made by the models.\n\n\nThe ROC curves for the Logistic Regression and XGBoost models illustrate their performance in distinguishing between positive and negative outcomes in stop and search operations. The area under the curve (AUC) is a key metric in these plots, with the Logistic Regression model achieving an AUC of 0.71 and the XGBoost model achieving a higher AUC of 0.81. The higher AUC for the XGBoost model indicates a better overall performance in correctly identifying true positives while minimizing false positives compared to the Logistic Regression model. This demonstrates that the XGBoost model is more effective in differentiating between individuals who possess illegal items and those who do not, which can significantly impact the effectiveness and efficiency of stop and search operations.\n\n\n\nFigure 4: ROC curves showing the true positive rate against the false positive rate for the Logistic Regression and XGBoost models."
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Stop and Searchs",
    "section": "",
    "text": "The data exhibits significant daily fluctuations, with counts ranging from as low as zero (COVID) to peaks exceeding 1000 SAS in a single day. There is a general declining trend over the observed period, especially noticeable from mid-2022 onwards. Spikes in SAS activity occur sporadically, suggesting specific events or periods with heightened enforcement. The overall trend shows a gradual decrease in daily SAS counts, stabilising at lower values by the end of 2023 and early 2024.\n\n\n\nFigure 1: Line chart identifying daily SAS incident volume. The plot displays the number of Stop and Searches (SAS) conducted per day in London from January 2022 to January 2024. The y-axis represents the count of SAS, while the x-axis denotes the date.\n\n\nThe data shows an initial high level of SAS, with counts frequently exceeding 600 per day. This level starts to decline around mid-2022, with occasional peaks and troughs, indicating periods of increased and decreased enforcement activity.\nFrom mid-2023 onwards, the trend shows a more consistent decline, with daily counts stabilising at lower values by the end of 2023 and into early 2024, around the 300-400 range. The moving average helps highlight these trends by reducing the noise from daily fluctuations, providing a clearer picture of the overall changes in SAS activity over the two-year period.\n\n\n\nFigure 2: Line chart identifying 7 day average daily SAS success rate. This plot displays the number of Stop and Searches (SAS) conducted per day in London from January 2022 to January 2024, with a 7-day moving average applied to smooth the data and better identify trends. The y-axis represents the count of SAS, while the x-axis denotes the date. The application of the 7-day moving average reveals a more discernible trend compared to the raw daily counts.\n\n\nThe data reveals that Thursday and Friday have the highest number of SAS, each exceeding 55,000, followed closely by Wednesday. The counts for Monday and Tuesday are slightly lower, each around 45,000. Saturday shows a further decrease with the total just under 50,000, while Sunday has the lowest count, significantly dropping to approximately 35,000. This distribution suggests that SAS activities are more frequent on weekdays, particularly towards the latter half of the week, and less common during weekends.\n\n\n\nFigure 3: The bar chart illustrates the total number of SAS conducted in London, categorised by the day of the week. The y-axis represents the total count of SAS, while the x-axis lists the days of the week.\n\n\nThroughout the observed period, the further action rate fluctuates between approximately 0.60 and 0.80. There is a noticeable pattern of variability in the further action rate, with no clear long-term trend of increase or decrease. However, from mid-2023 onwards, the further action rate shows a slight downward trend, with more frequent dips below 0.70. Despite these fluctuations, the further action rate remains relatively stable, consistently hovering around the 0.70 mark throughout most of the period.\n\n\n\nFigure 4: Line chart identifying daily SAS success rate. The plot illustrates the daily further action rate of Stop and Searches (SAS) in London from January 2022 to January 2024. The y-axis represents the further action rate, while the x-axis denotes the date.\n\n\nhe 7-day moving average of the further action rate of SAS in London from January 2022 to January 2024 highlights clearer trends by smoothing daily fluctuations. Initially, the rate is relatively high in early 2022, often exceeding 0.72. Over time, it shows a gradual decline, stabilising around 0.70 by mid-2022. In 2023, variability increases, with a noticeable downward trend from mid-2023 onwards, frequently dipping below 0.70 and stabilising around 0.66 by early 2024. This moving average helps to identify these overall trends more effectively.\n While Figure 3 demonstrates significant differences in the total number of SAS conducted on different days of the week, Figure 5 shows the rate of further action outcomes (true outcomes) by day of the week, and it indicates much smaller variations.\nThe further action rates for each day are relatively consistent, all hovering around the 0.68 to 0.72 range. This suggests that despite the variations in the total number of SAS performed on different days, the effectiveness, in terms of further actions resulting from these searches, remains fairly stable throughout the week.\n\n\n\nFigure 5: Bar chart illustrating the rate of SAS further action conducted in London, categorised by day of the week. The y-axis represents the rate of further actions (true outcomes divided by total count), while the x-axis lists the days of the week.\n\n\n\n\n\nThe map reveals significant spatial variation in the frequency of SAS. Central and inner London boroughs such as Westminster, Camden, and Southwark exhibit the highest SAS counts, depicted in the darkest red shades. In contrast, outer boroughs like Richmond upon Thames, Kingston upon Thames, and Sutton show the lowest counts, illustrated in lighter shades. This pattern suggests a higher concentration of SAS activities in central urban areas, likely reflecting areas with higher population density and more active policing.\n Compared to the choropleth map, the heatmap offers a more nuanced view of SAS distribution by showing gradual changes in density rather than distinct boundaries between boroughs. This allows for a clearer identification of specific high-density areas within and across boroughs, providing a more detailed and accurate representation of where SAS activities are most concentrated in London. The smooth transitions and focus on density in the heatmap make it a more effective tool for visualising and analysing the spatial patterns of SAS.\n\n\n\nFigure 6: The heatmap displays hotspots for Stop and Searches (SAS) across different boroughs of London. The varying shades of blue represent the density of SAS activities, with darker shades indicating higher densities."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stop and Searchs",
    "section": "",
    "text": "Data\nThe data for this project was sourced from the data.police.uk API, which provides records of SAS incidents conducted by the police in London. This dataset includes several key attributes that are crucial for our analysis:\n\nDate and Time: The specific date and time when the stop and search occurred.\nLocation: The geographical location where the stop took place.\nReason for Stop: The official reason provided by the officers for conducting the stop and search.\nOutcome: The result of the stop and search, such as arrest, no further action, or other outcomes.\nDemographics: Information about the individual subjected to the stop and search, including age, gender, and ethnicity."
  }
]